import cv2
import re
import logging
import numpy as np
from ultralytics import YOLO
from paddleocr import PaddleOCR
import warnings

logging.getLogger("ppocr").setLevel(logging.WARNING)
warnings.filterwarnings("ignore", category=DeprecationWarning)


class LicensePlateOCR:
    def __init__(self):
        self.ocr = PaddleOCR(use_textline_orientation=True, lang='en')

    def preprocess_image(self, img):
        if img is None or img.size == 0: return None
        try:
            img = cv2.resize(img, None, fx=3, fy=3, interpolation=cv2.INTER_LINEAR)
            return img
        except Exception:
            return None

    def validate_text(self, text):
        # –£–±–∏—Ä–∞–µ–º –≤—Å—ë –ª–∏—à–Ω–µ–µ
        clean = re.sub(r'[^ABEKMHOPCTYX0123456789]', '', text.upper())

        # –î–ª–∏–Ω–∞ –ø–æ–ª–Ω–æ–≥–æ –Ω–æ–º–µ—Ä–∞ –†–§ (—Å —Ä–µ–≥–∏–æ–Ω–æ–º) - 8 –∏–ª–∏ 9 –∑–Ω–∞–∫–æ–≤.
        if 8 <= len(clean) <= 9:
            return clean
        return None

    def recognize(self, plate_img):
        if plate_img is None or plate_img.size == 0: return None

        if plate_img.shape[0] < 10 or plate_img.shape[1] < 10: return None

        processed_img = self.preprocess_image(plate_img)
        if processed_img is None: return None

        try:
            result = self.ocr.ocr(processed_img)
            if not result: return None

            data = result[0]

            if isinstance(data, dict):
                rec_texts = data.get('rec_texts', [])
                rec_scores = data.get('rec_scores', [])
                rec_boxes = data.get('rec_boxes', [])

                if not rec_texts: return None

                blocks = []
                for i, text in enumerate(rec_texts):
                    score = rec_scores[i]
                    box = rec_boxes[i]

                    # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –û–®–ò–ë–ö–ò –ó–î–ï–°–¨ ---
                    try:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ box[0] —Å–ø–∏—Å–∫–æ–º/–º–∞—Å—Å–∏–≤–æ–º (–ø–æ–ª–∏–≥–æ–Ω) –∏–ª–∏ —á–∏—Å–ª–æ–º (bbox)
                        if hasattr(box[0], '__len__'):
                            x_coord = box[0][0]  # –§–æ—Ä–º–∞—Ç [[x,y], [x,y]...]
                        else:
                            x_coord = box[0]  # –§–æ—Ä–º–∞—Ç [x, y, x2, y2]
                    except Exception:
                        x_coord = 0  # –ù–∞ —Å–ª—É—á–∞–π —Å–±–æ—è —Å—Ç–∞–≤–∏–º –≤ –Ω–∞—á–∞–ª–æ
                    # --------------------------------

                    if score > 0.4:
                        blocks.append((text, x_coord))

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ
                blocks.sort(key=lambda b: b[1])

                # –°–∫–ª–µ–∏–≤–∞–µ–º
                full_text_raw = "".join([b[0] for b in blocks])

                print(f"üëÅÔ∏è –°–ö–õ–ï–ï–ù–û: '{full_text_raw}'")

                valid = self.validate_text(full_text_raw)
                if valid:
                    return valid

            return None

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
            return None


def main():
    print("üöÄ –ó–ê–ü–£–°–ö –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò...")

    VIDEO_SOURCE = 0
    YOLO_MODEL = 'best.pt'

    cap = cv2.VideoCapture(VIDEO_SOURCE)
    if not cap.isOpened():
        print("–û—à–∏–±–∫–∞ –∫–∞–º–µ—Ä—ã")
        return

    try:
        detector = YOLO(YOLO_MODEL)
        ocr_reader = LicensePlateOCR()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
        return

    frame_count = 0

    # –í–ê–ñ–ù–û: –£–±—Ä–∞–ª–∏ –ø—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–æ–≤, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–∑—É
    SKIP_FRAMES = 1

    while True:
        ret, frame = cap.read()
        if not ret: break

        frame_count += 1
        h_frame, w_frame, _ = frame.shape

        results = detector(frame, stream=True, verbose=False, conf=0.3)

        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])

                # –û—Ç—Å—Ç—É–ø—ã 5 –ø–∏–∫—Å–µ–ª–µ–π
                pad = 5
                x1 = max(0, x1 - pad)
                y1 = max(0, y1 - pad)
                x2 = min(w_frame, x2 + pad)
                y2 = min(h_frame, y2 + pad)

                # –†–∏—Å—É–µ–º —Å–∏–Ω—é—é —Ä–∞–º–∫—É (–æ–Ω–∞ —É –≤–∞—Å –µ—Å—Ç—å)
                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

                plate_img = frame[y1:y2, x1:x2]

                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å
                text = ocr_reader.recognize(plate_img)
                if text:
                    print(f"‚úÖ‚úÖ‚úÖ –ù–û–ú–ï–†: {text}")
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(frame, text, (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 3)

        cv2.imshow('Smart Checkpoint', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == '__main__':
    main()