import kagglehub
import cv2
import os
import shutil
from pathlib import Path
import yaml
import numpy as np
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import xml.etree.ElementTree as ET


class CarPlateDatasetProcessorXML:
    def __init__(self):
        self.dataset_path = None
        self.yolo_path = Path('./car_plate_yolo_dataset')

    def download_dataset(self):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ car-plate-detection"""
        print("üì• –°–ö–ê–ß–ò–í–ê–ù–ò–ï –î–ê–¢–ê–°–ï–¢–ê CAR-PLATE-DETECTION")
        print("=" * 50)

        try:
            self.dataset_path = kagglehub.dataset_download("andrewmvd/car-plate-detection")
            print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–∫–∞—á–∞–Ω: {self.dataset_path}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
            return False

    def explore_dataset(self):
        """–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print("\nüîç –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –î–ê–¢–ê–°–ï–¢–ê")
        print("=" * 45)

        if not self.dataset_path:
            print("‚ùå –î–∞—Ç–∞—Å–µ—Ç –Ω–µ —Å–∫–∞—á–∞–Ω")
            return False

        dataset_dir = Path(self.dataset_path)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        for item in dataset_dir.iterdir():
            if item.is_dir():
                print(f"üìÅ {item.name}/")
                files = list(item.iterdir())
                for file in files[:5]:
                    print(f"   üìÑ {file.name}")
                if len(files) > 5:
                    print(f"   ... –∏ –µ—â–µ {len(files) - 5} —Ñ–∞–π–ª–æ–≤")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–æ–∫
        annotations_dir = dataset_dir / 'annotations'
        images_dir = dataset_dir / 'images'

        if annotations_dir.exists() and images_dir.exists():
            xml_files = list(annotations_dir.glob('*.xml'))
            image_files = list(images_dir.glob('*.*'))
            print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            print(f"   XML –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π: {len(xml_files)}")
            print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")
            return True
        else:
            print("‚ùå –ü–∞–ø–∫–∏ annotations –∏–ª–∏ images –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False

    def parse_xml_annotation(self, xml_path):
        """–ü–∞—Ä—Å–∏–Ω–≥ XML –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏"""
        try:
            tree = ET.parse(xml_path)
            root = tree.getroot()

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
            filename = root.find('filename').text
            size = root.find('size')
            width = int(size.find('width').text)
            height = int(size.find('height').text)

            # –ò—â–µ–º –æ–±—ä–µ–∫—Ç—ã (–Ω–æ–º–µ—Ä–∞)
            objects = []
            for obj in root.findall('object'):
                name = obj.find('name').text
                bndbox = obj.find('bndbox')

                xmin = int(bndbox.find('xmin').text)
                ymin = int(bndbox.find('ymin').text)
                xmax = int(bndbox.find('xmax').text)
                ymax = int(bndbox.find('ymax').text)

                objects.append({
                    'class': name,
                    'bbox': [xmin, ymin, xmax, ymax]
                })

            return {
                'filename': filename,
                'width': width,
                'height': height,
                'objects': objects
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {xml_path}: {e}")
            return None

    def process_annotations(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ XML –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –∏ —Å–æ–∑–¥–∞–Ω–∏–µ YOLO —Ñ–æ—Ä–º–∞—Ç–∞"""
        print("\nüîÑ –û–ë–†–ê–ë–û–¢–ö–ê XML –ê–ù–ù–û–¢–ê–¶–ò–ô")
        print("=" * 40)

        dataset_dir = Path(self.dataset_path)
        annotations_dir = dataset_dir / 'annotations'
        images_dir = dataset_dir / 'images'

        if not annotations_dir.exists() or not images_dir.exists():
            print("‚ùå –ü–∞–ø–∫–∏ annotations –∏–ª–∏ images –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False

        # –°–æ–∑–¥–∞–µ–º YOLO —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        self.create_yolo_structure()

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ XML —Ñ–∞–π–ª—ã
        xml_files = list(annotations_dir.glob('*.xml'))
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ XML —Ñ–∞–π–ª–æ–≤: {len(xml_files)}")

        # –ü–∞—Ä—Å–∏–º –≤—Å–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
        images_data = {}
        valid_count = 0

        for xml_file in tqdm(xml_files, desc="–ü–∞—Ä—Å–∏–Ω–≥ XML"):
            annotation = self.parse_xml_annotation(xml_file)
            if annotation and annotation['objects']:
                images_data[annotation['filename']] = annotation
                valid_count += 1

        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ: {valid_count}/{len(xml_files)}")

        if valid_count == 0:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π")
            return False

        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val/test
        image_names = list(images_data.keys())
        train_names, temp_names = train_test_split(image_names, test_size=0.3, random_state=42)
        val_names, test_names = train_test_split(temp_names, test_size=0.5, random_state=42)

        print(f"üéØ –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: Train={len(train_names)}, Val={len(val_names)}, Test={len(test_names)}")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        self.process_split('train', train_names, images_data, images_dir)
        self.process_split('val', val_names, images_data, images_dir)
        self.process_split('test', test_names, images_data, images_dir)

        # –°–æ–∑–¥–∞–µ–º YAML –∫–æ–Ω—Ñ–∏–≥
        self.create_yaml_config()

        return True

    def create_yolo_structure(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫ YOLO"""
        print("üìÅ –°–û–ó–î–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ YOLO")

        folders = [
            'images/train', 'images/val', 'images/test',
            'labels/train', 'labels/val', 'labels/test',
            'images_processed/train', 'images_processed/val', 'images_processed/test'
        ]

        for folder in folders:
            (self.yolo_path / folder).mkdir(parents=True, exist_ok=True)
            print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–∞: {folder}")

    def process_split(self, split_name, image_names, images_data, images_dir):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è (train/val/test)"""
        print(f"\nüîß –û–±—Ä–∞–±–æ—Ç–∫–∞ {split_name}...")

        processed_count = 0
        for image_name in tqdm(image_names, desc=f"  {split_name}"):
            # –ò—â–µ–º —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_path = images_dir / image_name

            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –µ—Å–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
            if not image_path.exists():
                for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG']:
                    potential_path = images_dir / f"{Path(image_name).stem}{ext}"
                    if potential_path.exists():
                        image_path = potential_path
                        break

            if not image_path.exists():
                continue

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = cv2.imread(str(image_path))
            if image is None:
                continue

            annotation = images_data[image_name]
            img_height, img_width = annotation['height'], annotation['width']

            # –°–æ–∑–¥–∞–µ–º YOLO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
            yolo_annotations = []
            for obj in annotation['objects']:
                xmin, ymin, xmax, ymax = obj['bbox']

                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ YOLO —Ñ–æ—Ä–º–∞—Ç
                x_center = (xmin + xmax) / 2 / img_width
                y_center = (ymin + ymax) / 2 / img_height
                width = (xmax - xmin) / img_width
                height = (ymax - ymin) / img_height

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
                if (0 <= x_center <= 1 and 0 <= y_center <= 1 and
                        0 <= width <= 1 and 0 <= height <= 1):
                    # –ö–ª–∞—Å—Å 0 –¥–ª—è –Ω–æ–º–µ—Ä–Ω–æ–≥–æ –∑–Ω–∞–∫–∞
                    yolo_annotations.append(f"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

            if not yolo_annotations:
                continue

            # –ö–æ–ø–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            dest_image_path = self.yolo_path / 'images' / split_name / image_path.name
            shutil.copy2(image_path, dest_image_path)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–µ—Ä—ã–π + –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
            processed_image = self.process_image_for_training(image)
            processed_image_path = self.yolo_path / 'images_processed' / split_name / image_path.name
            cv2.imwrite(str(processed_image_path), processed_image)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
            annotation_path = self.yolo_path / 'labels' / split_name / f"{image_path.stem}.txt"
            with open(annotation_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(yolo_annotations))

            processed_count += 1

        print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

    def process_image_for_training(self, image):
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        –ë–æ–ª–µ–µ –º—è–≥–∫–∏–µ –º–µ—Ç–æ–¥—ã, —Å–æ—Ö—Ä–∞–Ω—è—é—â–∏–µ —á–∏—Ç–∞–µ–º–æ—Å—Ç—å –Ω–æ–º–µ—Ä–æ–≤
        """
        # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–µ—Ä—ã–π (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –æ—Ç—Ç–µ–Ω–∫–∏)
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image

        # 2. –ú—è–≥–∫–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
        denoised = cv2.fastNlMeansDenoising(gray, None, h=5, templateWindowSize=7, searchWindowSize=21)

        # 3. –£–º–µ—Ä–µ–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8, 8))  # –£–º–µ–Ω—å—à–µ–Ω clipLimit
        contrast_enhanced = clahe.apply(denoised)

        # 4. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–µ—Ä–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏–∏
        return contrast_enhanced

    def create_yaml_config(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ YAML –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        config = {
            'path': str(self.yolo_path.resolve()),
            'train': 'images_processed/train',  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            'val': 'images_processed/val',
            'test': 'images_processed/test',
            'nc': 1,
            'names': ['license_plate']
        }

        with open('car_plate_dataset.yaml', 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False)

        print(f"\n‚úÖ YAML –∫–æ–Ω—Ñ–∏–≥ —Å–æ–∑–¥–∞–Ω: car_plate_dataset.yaml")

    def show_processing_example(self):
        """–ü–æ–∫–∞–∑ –ø—Ä–∏–º–µ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        print("\nüé® –ü–†–ò–ú–ï–† –û–ë–†–ê–ë–û–¢–ö–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø")
        print("=" * 40)

        # –ù–∞—Ö–æ–¥–∏–º –ª—é–±–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        train_images = list((self.yolo_path / 'images' / 'train').glob('*.*'))
        if not train_images:
            print("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return

        example_image_path = train_images[0]
        original = cv2.imread(str(example_image_path))
        processed = self.process_image_for_training(original)

        print(f"üìê –û—Ä–∏–≥–∏–Ω–∞–ª: {original.shape}")
        print(f"üìê –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ: {processed.shape}")
        print(f"üéØ –¢–∏–ø: {'–°–µ—Ä–æ–µ' if len(processed.shape) == 2 else '–¶–≤–µ—Ç–Ω–æ–µ'}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
        cv2.imwrite('example_original.jpg', original)
        cv2.imwrite('example_processed.jpg', processed)
        print("üí° –ü—Ä–∏–º–µ—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: example_original.jpg, example_processed.jpg")

    def analyze_dataset_quality(self):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print("\nüìä –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –î–ê–¢–ê–°–ï–¢–ê")
        print("=" * 35)

        dataset_dir = Path(self.dataset_path)
        annotations_dir = dataset_dir / 'annotations'

        if not annotations_dir.exists():
            print("‚ùå –ü–∞–ø–∫–∞ annotations –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return

        xml_files = list(annotations_dir.glob('*.xml'))

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ XML —Ñ–∞–π–ª–æ–≤
        sizes = []
        objects_per_image = []

        for xml_file in xml_files[:100]:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 100
            annotation = self.parse_xml_annotation(xml_file)
            if annotation:
                sizes.append((annotation['width'], annotation['height']))
                objects_per_image.append(len(annotation['objects']))

        if sizes:
            avg_width = np.mean([s[0] for s in sizes])
            avg_height = np.mean([s[1] for s in sizes])
            avg_objects = np.mean(objects_per_image)

            print(f"üìê –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {avg_width:.0f}x{avg_height:.0f}")
            print(f"üéØ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–º–µ—Ä–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {avg_objects:.2f}")
            print(f"üìä –†–∞–∑–º–µ—Ä—ã –≤—ã–±–æ—Ä–∫–∏: {len(sizes)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    processor = CarPlateDatasetProcessorXML()

    # 1. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    if not processor.download_dataset():
        return

    # 2. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    if not processor.explore_dataset():
        return

    # 3. –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞
    processor.analyze_dataset_quality()

    # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –∏ —Å–æ–∑–¥–∞–Ω–∏–µ YOLO —Ñ–æ—Ä–º–∞—Ç–∞
    if not processor.process_annotations():
        return

    # 5. –ü–æ–∫–∞–∑ –ø—Ä–∏–º–µ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    processor.show_processing_example()

    print(f"\nüéâ –î–ê–¢–ê–°–ï–¢ –ü–û–î–ì–û–¢–û–í–õ–ï–ù!")
    print(f"üìÅ –ü—É—Ç—å: {processor.yolo_path}")
    print(f"üöÄ –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: car_plate_dataset.yaml")


if __name__ == "__main__":
    main()